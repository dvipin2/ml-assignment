{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, matthews_corrcoef, confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfced450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load breast cancer dataset\n",
    "# this is already part of sklearn, so we can directly load it without needing to upload it as a csv file, will test it with uploaded test data later.\n",
    "brest_cancer_data = load_breast_cancer()\n",
    "X = pd.DataFrame(brest_cancer_data.data, columns=brest_cancer_data.feature_names)\n",
    "y = pd.Series(brest_cancer_data.target)\n",
    "\n",
    "# scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# split the data into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, train_size=0.8, random_state=42)\n",
    "training_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "print(f\"Training size: {training_size}, Test size: {test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the models using y_pred, y_true and y_proba\n",
    "def evaluate_model(y_true, y_pred, y_proba):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba) \n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc, mcc\n",
    "\n",
    "# plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb58367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a simple logistic regression model first, will add more models later.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_lr_pred = lr_model.predict(X_test)\n",
    "y_lr_prob = lr_model.predict_proba(X_test)[:, 1] # probability of the positive class\n",
    "\n",
    "print(y_lr_prob[:10])\n",
    "print(y_lr_pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lr_model, \"model/lr_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "evaluate_model(y_true=y_test, y_pred=y_lr_pred, y_proba=y_lr_prob)\n",
    "# plot confusion matrix \n",
    "plot_confusion_matrix(y_true=y_test, y_pred=y_lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement naive bayes classifier - gaussian or multinomial, will test both and see which one performs better on this dataset, will add more models later.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_nb_pred = nb_model.predict(X_test)\n",
    "y_nb_proba = nb_model.predict_proba(X_test)[:,1]\n",
    "# evaluate the model\n",
    "evaluate_model(y_true= y_test, y_pred=y_nb_pred, y_proba=y_nb_proba)\n",
    "\n",
    "# draw confusion matrix\n",
    "plot_confusion_matrix(y_true=y_test, y_pred=y_nb_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(nb_model, \"model/nb_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36908c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a Decision Tree Classifier now\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dcf = DecisionTreeClassifier(random_state=42, max_depth=4)\n",
    "dcf.fit(X=X_train, y=y_train)\n",
    "y_dcf_pred = dcf.predict(X=X_test)\n",
    "y_dcf_proba = dcf.predict_proba(X=X_test)[:,1] # since binary classificaiton\n",
    "\n",
    "# evaluate \n",
    "evaluate_model(y_true=y_test, y_pred=y_dcf_pred, y_proba=y_dcf_proba)\n",
    "\n",
    "# make confusion matrix\n",
    "plot_confusion_matrix(y_true=y_test, y_pred=y_dcf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(dcf, \"model/dcf_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379eb038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement KNN instance learning\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y=y_train)\n",
    "y_knn_pred = knn_model.predict(X_test)\n",
    "y_knn_proba = knn_model.predict_proba(X_test)[:, 1]\n",
    "# evaluate the matrix\n",
    "evaluate_model(y_true=y_test, y_pred=y_knn_pred, y_proba=y_knn_proba)\n",
    "\n",
    "#draw confusion matrix\n",
    "plot_confusion_matrix(y_true= y_test, y_pred=y_knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf626528",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(knn_model, \"model/knn_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# bagging with 25% of samples, take only sqrt(30) = 5 features to build the single decision stump (estimator)\n",
    "rfc_model = RandomForestClassifier(max_depth=4, n_estimators=100, \\\n",
    "                                   max_features=\"sqrt\", n_jobs=3, \\\n",
    "                                    random_state=42, max_samples=.25) \n",
    "rfc_model.fit(X=X_train, y=y_train)\n",
    "y_rfc_pred = rfc_model.predict(X=X_test)\n",
    "y_rfc_proba = rfc_model.predict_proba(X=X_test)[:,1]\n",
    "\n",
    "#evaluate the model\n",
    "evaluate_model(y_pred=y_rfc_pred, y_true=y_test, y_proba=y_rfc_proba)\n",
    "\n",
    "# plot confusion matrix \n",
    "plot_confusion_matrix(y_true=y_test, y_pred=y_rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model (pickle file)\n",
    "joblib.dump(rfc_model, \"model/rfc_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the last one finally ;) , XGBoost\n",
    "# sklearn doesn't provide one, we need to do it via xgboost lib\n",
    "#from xgboost import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
